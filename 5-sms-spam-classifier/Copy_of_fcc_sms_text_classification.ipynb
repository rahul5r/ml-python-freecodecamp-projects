{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RZOuS9LWQvv"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  !pip install tf-nightly\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "!pip install tensorflow-datasets\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMHwYXHXCar3"
   },
   "outputs": [],
   "source": [
    "# get data files\n",
    "!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
    "!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
    "\n",
    "train_file_path = \"train-data.tsv\"\n",
    "test_file_path = \"valid-data.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PUd62ZslAvlH"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_file_path, sep='\\t', header=None, names=[\"result\", \"sms\"])\n",
    "test_df  = pd.read_csv(test_file_path,  sep='\\t', header=None, names=[\"result\", \"sms\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NZIbK7TxAvhk"
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g7xTl2TvAvfQ"
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = text.replace(\"'\", '')\n",
    "    text = text.replace(\",\", '')\n",
    "    text = text.replace(\"!\", '')\n",
    "    text = text.replace(\"*\", '')\n",
    "    text = text.replace('.', '').lower()\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wuuDfhdYClg1"
   },
   "outputs": [],
   "source": [
    "def encode_label(x):\n",
    "    if x == 'ham':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "train_df['label'] = train_df['result'].apply(encode_label)\n",
    "test_df['label'] = test_df['result'].apply(encode_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hgUH7bvFC3O3"
   },
   "outputs": [],
   "source": [
    "vocab = {\"0\":0}\n",
    "\n",
    "num_words = 1\n",
    "for index, row in train_df.iterrows():\n",
    "    for word in tokenize(row['sms']):\n",
    "        if not word in vocab:\n",
    "            vocab[word] = num_words\n",
    "            num_words += 1\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    for word in tokenize(row['sms']):\n",
    "        if not word in vocab:\n",
    "            vocab[word] = num_words\n",
    "            num_words += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oBQRSrqGDaMN"
   },
   "outputs": [],
   "source": [
    "vocab['dear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bzuu6lttCv5X"
   },
   "outputs": [],
   "source": [
    "def encode_text(text):\n",
    "    tokens = tokenize(text)\n",
    "    ecoded_text = [vocab.get(word, 0) for word in tokens]\n",
    "    return ecoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g_h508FEClxO"
   },
   "outputs": [],
   "source": [
    "train_df['encode_text'] = train_df['sms'].apply(encode_text)\n",
    "test_df['encode_text'] = test_df['sms'].apply(encode_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kQHm_kiXFDJh"
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T3mdSI5iHWhk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get list of sequence lengths\n",
    "lengths = train_df['encode_text'].apply(len)\n",
    "\n",
    "# Calculate percentiles\n",
    "p70 = np.percentile(lengths, 70)\n",
    "p80 = np.percentile(lengths, 80)\n",
    "p90 = np.percentile(lengths, 90)\n",
    "p99 = np.percentile(lengths, 99)\n",
    "\n",
    "print(f\"70th percentile length: {p70}\")\n",
    "print(f\"80th percentile length: {p80}\")\n",
    "print(f\"90th percentile length: {p90}\")\n",
    "print(f\"99th percentile length: {p99}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfwiTU_QIUos"
   },
   "source": [
    "**If I wish to cover 99% percent of the data then maxlen should be 54**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j09j1XmaFDGL"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "maxlen = 54\n",
    "\n",
    "train_df['padded_text'] = pad_sequences(\n",
    "    train_df['encode_text'].tolist(),  # Convert Series to list of lists\n",
    "    maxlen=maxlen,\n",
    "    padding='pre',       # or 'post' if you prefer\n",
    "    truncating='pre',    # or 'post'\n",
    "    value=0              # Use 0 for padding token ID\n",
    ").tolist()  # Optional: convert back to list so it fits nicely in a DataFrame\n",
    "\n",
    "test_df['padded_text'] = pad_sequences(\n",
    "    test_df['encode_text'].tolist(),  # Convert Series to list of lists\n",
    "    maxlen=maxlen,\n",
    "    padding='pre',       # or 'post' if you prefer\n",
    "    truncating='pre',    # or 'post'\n",
    "    value=0              # Use 0 for padding token ID\n",
    ").tolist()  # Optional: convert back to list so it fits nicely in a DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hmmjURUUFDD_"
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yCPpGVnNFDB9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array(train_df['padded_text'].tolist())\n",
    "y = np.array(train_df['label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G8K-cUyMFC_t"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "vocab_size = len(vocab) + 1  # +1 if you used 0 for padding\n",
    "embedding_dim = 50\n",
    "maxlen = X.shape[1]  # padded sequence length\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen),\n",
    "    LSTM(64),\n",
    "    Dense(1, activation='sigmoid')  # For binary classification\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BDbdUFFfFC9l"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, batch_size=32, epochs=5, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SKcnujteJQ3p"
   },
   "outputs": [],
   "source": [
    "X_test = np.array(test_df['padded_text'].tolist())\n",
    "y_test = np.array(test_df['label'].tolist())\n",
    "\n",
    "model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J9tD9yACG6M9"
   },
   "outputs": [],
   "source": [
    "# function to predict messages based on model\n",
    "# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n",
    "def predict_message(pred_text):\n",
    "    possible = [\"ham\", 'spam']\n",
    "    encoded_text = encode_text(pred_text)\n",
    "    padded_text = pad_sequences([encoded_text], maxlen=maxlen, padding='pre', truncating='pre', value=0)\n",
    "    prediction = model.predict(padded_text)\n",
    "    result = possible[(prediction[0]> 0.5).astype(\"int32\")[0]]\n",
    "    return result\n",
    "\n",
    "pred_text = \"how are you doing today?\"\n",
    "\n",
    "prediction = predict_message(pred_text)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dxotov85SjsC"
   },
   "outputs": [],
   "source": [
    "# Run this cell to test your function and model. Do not modify contents.\n",
    "def test_predictions():\n",
    "  test_messages = [\"how are you doing today\",\n",
    "                   \"sale today! to stop texts call 98912460324\",\n",
    "                   \"i dont want to go. can we try it a different day? available sat\",\n",
    "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
    "                   \"you have won Â£1000 cash! call to claim your prize.\",\n",
    "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
    "                   \"wow, is your arm alright. that happened to me one time too\"\n",
    "                  ]\n",
    "\n",
    "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
    "  passed = True\n",
    "\n",
    "  for msg, ans in zip(test_messages, test_answers):\n",
    "    prediction = predict_message(msg)\n",
    "    if prediction != ans:\n",
    "      passed = False\n",
    "\n",
    "  if passed:\n",
    "    print(\"You passed the challenge. Great job!\")\n",
    "  else:\n",
    "    print(\"You haven't passed yet. Keep trying.\")\n",
    "\n",
    "test_predictions()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {}
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
